# Хранения данных

Параметры хранилища данных:

* объем
* производительность
* отказоустойчивость
* латентность - задержки при ответе от хранилища

Устройства хранения

1. HDD - высокая производительность при последовательной записи (операция `seek` времязатратная)
2. SSD - высокая производительность, большая надежность. Блочная модель записи данных. TRIM

Данные на диске хранятся на разделах (`MBR`/`GPT`). 

У `MBR` есть ограничение на размер диска 2Тб. Также есть ограничение на количество разделов (4).  `GPT` количество разделов, которое влезает на диск, равно 128. 

Все разделы выравниваются по размеру секторов.

## SMART
`S.M.A.R.T.` - стандарт, поддерживаемый всеми жесткими дисками и SSD. Используется для отслеживания состояния диска. 

* `hdparm -i <disk_file>` - показывает конфигурацию диска
* `smartctl -a <disk_file>` - утилита для `SMART` диска

SMART параметры:
* `Power_On_Hours` - количество проработанных часов
* `G-Sense_Error_Rate` - количество ошибок произошедших при записи/считывании сектора. 
* `Rellocated_Sector_Ct` - количество секторов, которые были перенесены в резервное место по причине множества ошибок, связанных с считывание/записью. Если таких секторов становится все больше, то скоро скорее всего надо будет заменить диск
* `Current_Pending_Sector` - количество секторов, которые невозможно прочитать и соответственно перенести в резервное место. Соответственно, эти сектора потеряны на диске. Очень важный параметр!
* `Temperature_Celcius` - температура диска

## Элеваторы
Элеватор - алгоритм, который отвечает за движение головки диска, для обчеспечения возможности чтения и записи на диск. Движение, естественно, должно быть оптимальным.
>The elevator algorithm (also SCAN) is a disk scheduling algorithm to determine the motion of the disk's arm and head in servicing read and write requests.

Виды
* Noop - отправляет запросы на диск в том порядке, в котором он их получает. Нет оптимизации.
* Deadline - пытается обеспечить латентность дисковых операций не выше пороговой. Гарант латентности. (работает в базах данных)
* Cfq - распределяет ресурсы диска среди приложений наиболее равномерной


```bash
cat /sys/block/sda/queue/scheduler
echo noop > /sys/block/sda/queue/scheduler
```

Или в конфигурации загрузки ядра - `/boot/grub/grub.cfg`

## RAID

RAID - Redundant Array of Independent Disks. Проектировался для защиты от потери данных при выходе из строя отдельных дисков, повышение производительности раздела.

Виды RAID (наиболее используемые):
* `RAID 0` (stripe) - данные делятся на блоки, которые раскидываются на диски. Не совсем RAID (так как нет избыточности). Не обеспечивает отказоустойчивости.

* `RAID 1` (mirror) - все диски содержат одни и те же данные (блок кадется на каждый диск). Применяется для разделов с ОС. 
* `RAID 5` - состоит из `N` дисков, сумарный объем равен объему `N-1` диска. Часто используется для хранения резервныхх копий. Если сломается всего один диск, RAID будет работать очень медленно
* `RAID 6` - хранится не одна контрольная сумма, а две. Объем = `N-2`. Производительность примерно такая же как у `RAID 5`, зато больше надежность
* `RAID 10` (stripe mirror'ов) - используется для баз данных

<img src="https://goo.gl/FybZPE" height="200">
<img src="http://www.medianas.ru/published/publicdata/MEDIAN66WA/attachments/SC/images/1raid-5-1.png" height="200">
<img src="https://www.lacie.com/files/lacie-content/manuals/lacie-raid-manager-user-manual/_shared/images/raid-6.jpg" height="200">

RAID:
* программный
* аппаратный

### Практика
**Блочное устройство** - вид файла устройств в Unix системах, обеспечивающий интерфейс к устройству (реальному или виртуальному), в виде файла в файловой системе.

`/dev/zero` - блочное устройство, который содержит только символы \0

```bash
# записываем конфигурацию в файл /tmp/parts.txt
cat << EOF > /tmp/parts.txt
unit: sectors
/dev/loop0p1 : start=     2048, size=  1046528, Id=fd
/dev/loop0p2 : start=        0, size=        0, Id= 0
/dev/loop0p3 : start=        0, size=        0, Id= 0
/dev/loop0p4 : start=        0, size=        0, Id= 0
EOF

for i in {0..3} ; do
	# создаем пустой файл, заполненный \0, размером 512*1MB
    dd if=/dev/zero of=/tmp/test.bin.$i bs=1M count=512
    # ассоциируем loop device с бинарным файлом
    losetup /dev/loop$i /tmp/test.bin.$i 
    # делаем разметку на блочном устройстве по конфигу из parts.txt
    sfdisk --force /dev/loop$i < /tmp/parts.txt
	# информируем ОС об изменении таблицы разделов на блочном уст-ве
    partprobe /dev/loop$i
done
```
В итоге мы имеем 4 loop-back устройства с размеченным первым разделом. Создадим программный `RAID 10` из 4 устройства
```bash
mdadm --create /dev/md10 --level 10 --raid-devices=4 /dev/loop{0..3}p1
mkfs.ext4 /dev/md10
mount /dev/md10 /mnt
```
Посмотрим информацию о рейде
```bash
mdadm -D /dev/md10
```
И проверим текщий статус
```bash
cat /proc/mdstat
```
Сэмулируем траблы с дисками из рейда. Обрати внимание, что теперь статус рейда станет `Degraged`
```bash
# один диск вышел из строя
mdadm /dev/md10 -f /dev/loop0p1
# удалим этот диск из рейда
mdadm /dev/md10 -r /dev/loop0p1
```
Но, так как мы создавали `RAID 10`, то выход одного из дисков не проблема. По прежнему можно записывать данный в рейд

Разбор рейда
```bash
umount /mnt
mdadm –stop /dev/md10
for i in {0..3} ; do losetup -d /dev/loop$i ; done
rm -f /tmp/test.bin.{0..3}
```
## LVM снепшоты

## ISCSI

